{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing need library"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T19:05:14.673232Z",
     "start_time": "2024-08-15T19:05:11.075774Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Set hyperparameters"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T19:05:17.223575Z",
     "start_time": "2024-08-15T19:05:17.219966Z"
    }
   },
   "source": [
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check hardware accessbility(CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T19:05:20.274740Z",
     "start_time": "2024-08-15T19:05:19.954886Z"
    }
   },
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "torch.device(device)\n",
    "torch.cuda.set_device(0)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_setDevice'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m device\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     10\u001B[0m torch\u001B[38;5;241m.\u001B[39mdevice(device)\n\u001B[0;32m---> 11\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_device\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Kharazmi/venv/lib/python3.9/site-packages/torch/cuda/__init__.py:408\u001B[0m, in \u001B[0;36mset_device\u001B[0;34m(device)\u001B[0m\n\u001B[1;32m    406\u001B[0m device \u001B[38;5;241m=\u001B[39m _get_device_index(device)\n\u001B[1;32m    407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 408\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cuda_setDevice\u001B[49m(device)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'torch._C' has no attribute '_cuda_setDevice'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define transforms for data augmentation and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)), # Randomly crop and resize with random zoom (80% - 100% of original size)\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(25), # Random rotation by up to 10 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2), # Randomly adjust brightness and contrast\n",
    "    transforms.RandomAffine(0, translate=(0.1,0.1), scale=(0.9, 1.1)), # Random affine transformation (rotate, translate, scale)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform_val_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load your dataset from local PC and define data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the whole folder images \n",
    "dataset = ImageFolder(root='/home/mehdirexon/Desktop/vsc/image classifcation/dataset/plastic', transform=transform)\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow_grid(images, labels, classes, num_rows=2, num_cols=4, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], one_channel=False):\n",
    "    num_images = len(images)\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(7, 7))\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            index = i * num_cols + j\n",
    "            if index < num_images:\n",
    "                img = images[index]\n",
    "                label = labels[index]\n",
    "                if one_channel:\n",
    "                    img = img.mean(dim=0)\n",
    "                else:\n",
    "                    # Unnormalize the image\n",
    "                    for t, m, s in zip(img, mean, std):\n",
    "                        t.mul_(s).add_(m)\n",
    "                img = img / 2 + 0.5     # Unnormalize\n",
    "                npimg = img.numpy()\n",
    "                if one_channel:\n",
    "                    axes[i, j].imshow(npimg, cmap=\"Greys\")\n",
    "                else:\n",
    "                    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "                    npimg = np.clip(npimg, 0, 1)    # Clip to [0, 1] in case of numerical errors\n",
    "                    axes[i, j].imshow(npimg)\n",
    "                axes[i, j].set_title(classes[label])\n",
    "                axes[i, j].axis('off')\n",
    "            else:\n",
    "                axes[i, j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images in a grid format with specified number of rows and columns\n",
    "matplotlib_imshow_grid(images, labels, dataset.classes, num_rows=5, num_cols=5, one_channel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the ResNet18 model, loss function and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T19:06:55.436373Z",
     "start_time": "2024-08-15T19:05:39.846117Z"
    }
   },
   "source": [
    "model = torchvision.models.mobilenet_v2(weights='MobileNet_V2_Weights.DEFAULT')\n",
    "dataiter = iter(train_loader)\n",
    "\n",
    "inputs, labels = next(dataiter)\n",
    "inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(dataset.classes))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /Users/mehdirexon/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 60] Operation timed out>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTimeoutError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:1346\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1345\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1346\u001B[0m     \u001B[43mh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1347\u001B[0m \u001B[43m              \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhas_header\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTransfer-encoding\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1348\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1257\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1256\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1257\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1303\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1302\u001B[0m     body \u001B[38;5;241m=\u001B[39m _encode(body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1303\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mendheaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1252\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n\u001B[0;32m-> 1252\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1012\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1011\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n\u001B[0;32m-> 1012\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1014\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1015\u001B[0m \n\u001B[1;32m   1016\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:952\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    951\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n\u001B[0;32m--> 952\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    953\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1419\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1417\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnect to a host on a given (SSL) port.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1419\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1421\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tunnel_host:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:923\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    922\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 923\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_connection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msource_address\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock\u001B[38;5;241m.\u001B[39msetsockopt(socket\u001B[38;5;241m.\u001B[39mIPPROTO_TCP, socket\u001B[38;5;241m.\u001B[39mTCP_NODELAY, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:843\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    842\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 843\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m    844\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    845\u001B[0m     \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:831\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    830\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[0;32m--> 831\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "\u001B[0;31mTimeoutError\u001B[0m: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mURLError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtorchvision\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmobilenet_v2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMobileNet_V2_Weights.DEFAULT\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m dataiter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(train_loader)\n\u001B[1;32m      4\u001B[0m inputs, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(dataiter)\n",
      "File \u001B[0;32m~/PycharmProjects/Kharazmi/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:142\u001B[0m, in \u001B[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    135\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    136\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msequence_to_str(\u001B[38;5;28mtuple\u001B[39m(keyword_only_kwargs\u001B[38;5;241m.\u001B[39mkeys()),\u001B[38;5;250m \u001B[39mseparate_last\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mand \u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m as positional \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    137\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    138\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minstead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    139\u001B[0m     )\n\u001B[1;32m    140\u001B[0m     kwargs\u001B[38;5;241m.\u001B[39mupdate(keyword_only_kwargs)\n\u001B[0;32m--> 142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Kharazmi/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:228\u001B[0m, in \u001B[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m kwargs[pretrained_param]\n\u001B[1;32m    226\u001B[0m     kwargs[weights_param] \u001B[38;5;241m=\u001B[39m default_weights_arg\n\u001B[0;32m--> 228\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbuilder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Kharazmi/venv/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py:258\u001B[0m, in \u001B[0;36mmobilenet_v2\u001B[0;34m(weights, progress, **kwargs)\u001B[0m\n\u001B[1;32m    255\u001B[0m model \u001B[38;5;241m=\u001B[39m MobileNetV2(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    257\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 258\u001B[0m     model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mweights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprogress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/PycharmProjects/Kharazmi/venv/lib/python3.9/site-packages/torchvision/models/_api.py:90\u001B[0m, in \u001B[0;36mWeightsEnum.get_state_dict\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_state_dict\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Mapping[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[0;32m---> 90\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_state_dict_from_url\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Kharazmi/venv/lib/python3.9/site-packages/torch/hub.py:766\u001B[0m, in \u001B[0;36mload_state_dict_from_url\u001B[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001B[0m\n\u001B[1;32m    764\u001B[0m         r \u001B[38;5;241m=\u001B[39m HASH_REGEX\u001B[38;5;241m.\u001B[39msearch(filename)  \u001B[38;5;66;03m# r is Optional[Match[str]]\u001B[39;00m\n\u001B[1;32m    765\u001B[0m         hash_prefix \u001B[38;5;241m=\u001B[39m r\u001B[38;5;241m.\u001B[39mgroup(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m r \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 766\u001B[0m     \u001B[43mdownload_url_to_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcached_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhash_prefix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprogress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    768\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_legacy_zip_format(cached_file):\n\u001B[1;32m    769\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _legacy_zip_load(cached_file, model_dir, map_location, weights_only)\n",
      "File \u001B[0;32m~/PycharmProjects/Kharazmi/venv/lib/python3.9/site-packages/torch/hub.py:620\u001B[0m, in \u001B[0;36mdownload_url_to_file\u001B[0;34m(url, dst, hash_prefix, progress)\u001B[0m\n\u001B[1;32m    618\u001B[0m file_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    619\u001B[0m req \u001B[38;5;241m=\u001B[39m Request(url, headers\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.hub\u001B[39m\u001B[38;5;124m\"\u001B[39m})\n\u001B[0;32m--> 620\u001B[0m u \u001B[38;5;241m=\u001B[39m \u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    621\u001B[0m meta \u001B[38;5;241m=\u001B[39m u\u001B[38;5;241m.\u001B[39minfo()\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(meta, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgetheaders\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:214\u001B[0m, in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    213\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[0;32m--> 214\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopener\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:517\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    514\u001B[0m     req \u001B[38;5;241m=\u001B[39m meth(req)\n\u001B[1;32m    516\u001B[0m sys\u001B[38;5;241m.\u001B[39maudit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124murllib.Request\u001B[39m\u001B[38;5;124m'\u001B[39m, req\u001B[38;5;241m.\u001B[39mfull_url, req\u001B[38;5;241m.\u001B[39mdata, req\u001B[38;5;241m.\u001B[39mheaders, req\u001B[38;5;241m.\u001B[39mget_method())\n\u001B[0;32m--> 517\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[38;5;66;03m# post-process response\u001B[39;00m\n\u001B[1;32m    520\u001B[0m meth_name \u001B[38;5;241m=\u001B[39m protocol\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_response\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:534\u001B[0m, in \u001B[0;36mOpenerDirector._open\u001B[0;34m(self, req, data)\u001B[0m\n\u001B[1;32m    531\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m    533\u001B[0m protocol \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mtype\n\u001B[0;32m--> 534\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_open\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\n\u001B[1;32m    535\u001B[0m \u001B[43m                          \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_open\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n\u001B[1;32m    537\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:494\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[0;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[1;32m    492\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m handler \u001B[38;5;129;01min\u001B[39;00m handlers:\n\u001B[1;32m    493\u001B[0m     func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[0;32m--> 494\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    495\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    496\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:1389\u001B[0m, in \u001B[0;36mHTTPSHandler.https_open\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttps_open\u001B[39m(\u001B[38;5;28mself\u001B[39m, req):\n\u001B[0;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhttp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mHTTPSConnection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1390\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_hostname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py:1349\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1346\u001B[0m         h\u001B[38;5;241m.\u001B[39mrequest(req\u001B[38;5;241m.\u001B[39mget_method(), req\u001B[38;5;241m.\u001B[39mselector, req\u001B[38;5;241m.\u001B[39mdata, headers,\n\u001B[1;32m   1347\u001B[0m                   encode_chunked\u001B[38;5;241m=\u001B[39mreq\u001B[38;5;241m.\u001B[39mhas_header(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransfer-encoding\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m   1348\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n\u001B[0;32m-> 1349\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m URLError(err)\n\u001B[1;32m   1350\u001B[0m     r \u001B[38;5;241m=\u001B[39m h\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m   1351\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n",
      "\u001B[0;31mURLError\u001B[0m: <urlopen error [Errno 60] Operation timed out>"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_values = []  # List to store the training loss values\n",
    "train_accuracy_values = []  # List to store the training accuracy values\n",
    "val_loss_values = []  # List to store the validation loss values\n",
    "val_accuracy_values = []  # List to store the validation accuracy values\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to save the checkpoint\n",
    "def save_checkpoint(model, optimizer, epoch, train_loss, train_accuracy, val_loss, val_accuracy, save_dir):\n",
    "    \"\"\"\n",
    "    Save model checkpoint.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): Model to be saved.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer state to be saved.\n",
    "        epoch (int): Current epoch.\n",
    "        train_loss (float): Training loss.\n",
    "        train_accuracy (float): Training accuracy.\n",
    "        val_loss (float): Validation loss.\n",
    "        val_accuracy (float): Validation accuracy.\n",
    "        save_dir (str): Directory path to save the checkpoint.\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_accuracy,\n",
    "    }\n",
    "    checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "# Training loop with checkpointing\n",
    "for epoch in range(NUM_EPOCHS):  # Number of epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        _, predicted_train = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted_train == labels).sum().item()\n",
    "        print(f\" mini batch: {i} / {len(train_loader)}\")\n",
    "    \n",
    "    epoch_train_loss = running_loss / len(train_loader)\n",
    "    epoch_train_accuracy = 100 * correct_train / total_train\n",
    "    \n",
    "    # Compute validation accuracy and loss\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "            _, predicted_val = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted_val == labels).sum().item()\n",
    "            \n",
    "    \n",
    "    epoch_val_loss = val_running_loss / len(val_loader)\n",
    "    epoch_val_accuracy = 100 * correct_val / total_val\n",
    "    \n",
    "    # Append values for visualization\n",
    "    train_loss_values.append(epoch_train_loss)\n",
    "    train_accuracy_values.append(epoch_train_accuracy)\n",
    "    val_loss_values.append(epoch_val_loss)\n",
    "    val_accuracy_values.append(epoch_val_accuracy)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} completed. Train Loss: {epoch_train_loss:.3f}, Train Accuracy: {epoch_train_accuracy:.2f}%, \"\n",
    "          f\"Val Loss: {epoch_val_loss:.3f}, Val Accuracy: {epoch_val_accuracy:.2f}%\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    save_checkpoint(model, optimizer, epoch, epoch_train_loss, epoch_train_accuracy, epoch_val_loss, epoch_val_accuracy, \"./epochs\")\n",
    "\n",
    "# Plot the loss and accuracy graphs\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss subplot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_loss_values, label='Train Loss')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_loss_values, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy subplot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_accuracy_values, label='Train Accuracy')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_accuracy_values, label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "checkpoint_path = '/home/mehdirexon/Desktop/vsc/image classifcation/epochs/checkpoint_epoch_12.pth'  # Change this to the path of your checkpoint file\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Load model state\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# If you also want to load the optimizer state\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Get the epoch at which the checkpoint was saved\n",
    "epoch_loaded = checkpoint['epoch']\n",
    "\n",
    "print(f\"Checkpoint loaded from {checkpoint_path}. Epoch: {epoch_loaded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation on validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy on validation set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy on test set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Calculating metrics and confusion matrix"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        true_labels.extend(labels.numpy())\n",
    "        predicted_labels.extend(predicted.numpy())\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.sum(np.array(true_labels) == np.array(predicted_labels)) / len(true_labels)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names = dataset.classes\n",
    "\n",
    "# Normalize confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, cmap='Blues', fmt=\".2f\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting single image (Laboratory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = Image.open('/home/mehdirexon/Desktop/vsc/image classifcation/pete.jpeg')  # Load your image\n",
    "image = transform(image)\n",
    "image = image.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(image)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "\n",
    "# Interpret the predictions\n",
    "predicted_class = predicted.item()\n",
    "class_probabilities = probabilities[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class,class_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'plastic_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
