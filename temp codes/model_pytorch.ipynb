{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing need library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Set hyperparameters"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check hardware accessbility(CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "torch.device(device)\n",
    "torch.cuda.set_device(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define transforms for data augmentation and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)), # Randomly crop and resize with random zoom (80% - 100% of original size)\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(25), # Random rotation by up to 10 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2), # Randomly adjust brightness and contrast\n",
    "    transforms.RandomAffine(0, translate=(0.1,0.1), scale=(0.9, 1.1)), # Random affine transformation (rotate, translate, scale)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform_val_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load your dataset from local PC and define data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the whole folder images \n",
    "dataset = ImageFolder(root='/home/mehdirexon/Desktop/vsc/image classifcation/dataset/plastic', transform=transform)\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow_grid(images, labels, classes, num_rows=2, num_cols=4, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], one_channel=False):\n",
    "    num_images = len(images)\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(7, 7))\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            index = i * num_cols + j\n",
    "            if index < num_images:\n",
    "                img = images[index]\n",
    "                label = labels[index]\n",
    "                if one_channel:\n",
    "                    img = img.mean(dim=0)\n",
    "                else:\n",
    "                    # Unnormalize the image\n",
    "                    for t, m, s in zip(img, mean, std):\n",
    "                        t.mul_(s).add_(m)\n",
    "                img = img / 2 + 0.5     # Unnormalize\n",
    "                npimg = img.numpy()\n",
    "                if one_channel:\n",
    "                    axes[i, j].imshow(npimg, cmap=\"Greys\")\n",
    "                else:\n",
    "                    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "                    npimg = np.clip(npimg, 0, 1)    # Clip to [0, 1] in case of numerical errors\n",
    "                    axes[i, j].imshow(npimg)\n",
    "                axes[i, j].set_title(classes[label])\n",
    "                axes[i, j].axis('off')\n",
    "            else:\n",
    "                axes[i, j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images in a grid format with specified number of rows and columns\n",
    "matplotlib_imshow_grid(images, labels, dataset.classes, num_rows=5, num_cols=5, one_channel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the ResNet18 model, loss function and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "dataiter = iter(train_loader)\n",
    "\n",
    "inputs, labels = next(dataiter)\n",
    "inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(dataset.classes))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_values = []  # List to store the training loss values\n",
    "train_accuracy_values = []  # List to store the training accuracy values\n",
    "val_loss_values = []  # List to store the validation loss values\n",
    "val_accuracy_values = []  # List to store the validation accuracy values\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to save the checkpoint\n",
    "def save_checkpoint(model, optimizer, epoch, train_loss, train_accuracy, val_loss, val_accuracy, save_dir):\n",
    "    \"\"\"\n",
    "    Save model checkpoint.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): Model to be saved.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer state to be saved.\n",
    "        epoch (int): Current epoch.\n",
    "        train_loss (float): Training loss.\n",
    "        train_accuracy (float): Training accuracy.\n",
    "        val_loss (float): Validation loss.\n",
    "        val_accuracy (float): Validation accuracy.\n",
    "        save_dir (str): Directory path to save the checkpoint.\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_accuracy,\n",
    "    }\n",
    "    checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "# Training loop with checkpointing\n",
    "for epoch in range(NUM_EPOCHS):  # Number of epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        _, predicted_train = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted_train == labels).sum().item()\n",
    "        print(f\" mini batch: {i} / {len(train_loader)}\")\n",
    "    \n",
    "    epoch_train_loss = running_loss / len(train_loader)\n",
    "    epoch_train_accuracy = 100 * correct_train / total_train\n",
    "    \n",
    "    # Compute validation accuracy and loss\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "            _, predicted_val = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted_val == labels).sum().item()\n",
    "            \n",
    "    \n",
    "    epoch_val_loss = val_running_loss / len(val_loader)\n",
    "    epoch_val_accuracy = 100 * correct_val / total_val\n",
    "    \n",
    "    # Append values for visualization\n",
    "    train_loss_values.append(epoch_train_loss)\n",
    "    train_accuracy_values.append(epoch_train_accuracy)\n",
    "    val_loss_values.append(epoch_val_loss)\n",
    "    val_accuracy_values.append(epoch_val_accuracy)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} completed. Train Loss: {epoch_train_loss:.3f}, Train Accuracy: {epoch_train_accuracy:.2f}%, \"\n",
    "          f\"Val Loss: {epoch_val_loss:.3f}, Val Accuracy: {epoch_val_accuracy:.2f}%\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    save_checkpoint(model, optimizer, epoch, epoch_train_loss, epoch_train_accuracy, epoch_val_loss, epoch_val_accuracy, \"./epochs\")\n",
    "\n",
    "# Plot the loss and accuracy graphs\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss subplot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_loss_values, label='Train Loss')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_loss_values, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy subplot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_accuracy_values, label='Train Accuracy')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_accuracy_values, label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "checkpoint_path = '/home/mehdirexon/Desktop/vsc/image classifcation/epochs/checkpoint_epoch_12.pth'  # Change this to the path of your checkpoint file\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Load model state\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# If you also want to load the optimizer state\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Get the epoch at which the checkpoint was saved\n",
    "epoch_loaded = checkpoint['epoch']\n",
    "\n",
    "print(f\"Checkpoint loaded from {checkpoint_path}. Epoch: {epoch_loaded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation on validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy on validation set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy on test set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Calculating metrics and confusion matrix"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        true_labels.extend(labels.numpy())\n",
    "        predicted_labels.extend(predicted.numpy())\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.sum(np.array(true_labels) == np.array(predicted_labels)) / len(true_labels)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names = dataset.classes\n",
    "\n",
    "# Normalize confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, cmap='Blues', fmt=\".2f\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting single image (Laboratory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = Image.open('/home/mehdirexon/Desktop/vsc/image classifcation/pete.jpeg')  # Load your image\n",
    "image = transform(image)\n",
    "image = image.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(image)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "\n",
    "# Interpret the predictions\n",
    "predicted_class = predicted.item()\n",
    "class_probabilities = probabilities[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class,class_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'plastic_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
